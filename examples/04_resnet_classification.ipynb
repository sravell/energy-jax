{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpu(id=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "jax.numpy.array(10)\n",
    "print(jax.devices())\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type=\"GPU\")\n",
    "import tensorflow_datasets as tfds\n",
    "import optax\n",
    "import equinox as eqx\n",
    "from energax import nns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from: https://jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html\n",
    "data_dir = \"/tmp/tfds\"\n",
    "\n",
    "# Fetch full datasets for evaluation\n",
    "# tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\n",
    "# You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy\n",
    "mnist_data, info = tfds.load(\n",
    "    name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True\n",
    ")\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data, test_data = mnist_data[\"train\"], mnist_data[\"test\"]\n",
    "num_labels = info.features[\"label\"].num_classes\n",
    "h, w, c = info.features[\"image\"].shape\n",
    "num_pixels = h * w * c\n",
    "\n",
    "# Full train set\n",
    "train_images, train_labels = train_data[\"image\"], train_data[\"label\"]\n",
    "train_images = jnp.tile(\n",
    "    jnp.reshape(train_images, (len(train_images), c, h, w)), [1, 3, 1, 1]\n",
    ")\n",
    "train_labels = jnp.array(train_labels).astype(\"int8\")\n",
    "# Full test set\n",
    "test_images, test_labels = test_data[\"image\"], test_data[\"label\"]\n",
    "test_images = jnp.tile(\n",
    "    jnp.reshape(test_images, (len(test_images), c, h, w)), [1, 3, 1, 1]\n",
    ")\n",
    "test_labels = jnp.array(test_labels).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (60000, 3, 28, 28) (60000,)\n",
      "Test: (10000, 3, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", train_images.shape, train_labels.shape)\n",
    "print(\"Test:\", test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/equinox/nn/_normalisation.py:84: UserWarning: LayerNorm(elementwise_affine=...) is deprecated in favour of LayerNorm(use_weight=...) and LayerNorm(use_bias=...)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = nns.resnet18(key=jax.random.PRNGKey(0), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 in 24.67 sec\n",
      "Training set accuracy 0.9485499858856201\n",
      "Test set accuracy 0.955299973487854\n",
      "0.25354156\n",
      "Epoch 1 in 18.66 sec\n",
      "Training set accuracy 0.9228833317756653\n",
      "Test set accuracy 0.9253999590873718\n",
      "0.28521124\n",
      "Epoch 2 in 18.23 sec\n",
      "Training set accuracy 0.9639833569526672\n",
      "Test set accuracy 0.963699996471405\n",
      "0.17131698\n",
      "Epoch 3 in 18.44 sec\n",
      "Training set accuracy 0.9675999879837036\n",
      "Test set accuracy 0.9692999720573425\n",
      "0.24755667\n",
      "Epoch 4 in 18.39 sec\n",
      "Training set accuracy 0.9816666841506958\n",
      "Test set accuracy 0.9809999465942383\n",
      "0.1749611\n",
      "Epoch 5 in 18.47 sec\n",
      "Training set accuracy 0.9700000286102295\n",
      "Test set accuracy 0.9692999720573425\n",
      "0.30764982\n",
      "Epoch 6 in 18.35 sec\n",
      "Training set accuracy 0.9630500078201294\n",
      "Test set accuracy 0.9630999565124512\n",
      "0.23849201\n",
      "Epoch 7 in 18.38 sec\n",
      "Training set accuracy 0.9869666695594788\n",
      "Test set accuracy 0.9833999872207642\n",
      "0.14752926\n",
      "Epoch 8 in 18.39 sec\n",
      "Training set accuracy 0.9830499887466431\n",
      "Test set accuracy 0.983199954032898\n",
      "0.15914722\n",
      "Epoch 9 in 18.36 sec\n",
      "Training set accuracy 0.9528833627700806\n",
      "Test set accuracy 0.9494999647140503\n",
      "0.36558858\n"
     ]
    }
   ],
   "source": [
    "# adapted from https://docs.kidger.site/equinox/examples/mnist/\n",
    "def loss_fn(model, x, y):\n",
    "    pred_y = eqx.filter_vmap(model, in_axes=(0, None))(x, jax.random.PRNGKey(42))\n",
    "    pred_y = jax.nn.log_softmax(pred_y)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(y, pred_y):\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def compute_accuracy(model, x, y):\n",
    "    pred_y = eqx.filter_vmap(model, in_axes=(0, None))(x, jax.random.PRNGKey(42))\n",
    "    pred_y = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(y == pred_y)\n",
    "\n",
    "\n",
    "loss = eqx.filter_jit(loss_fn)\n",
    "optim = optax.adamw(0.1)\n",
    "opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, opt_state, x, y):\n",
    "    loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "    updates, opt_state = optim.update(grads, opt_state, model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return model, opt_state, loss_value\n",
    "\n",
    "\n",
    "def get_train_batches():\n",
    "    # as_supervised=True gives us the (image, label) as a tuple instead of a dict\n",
    "    ds = tfds.load(name=\"mnist\", split=\"train\", as_supervised=True, data_dir=data_dir)\n",
    "    # You can build up an arbitrary tf.data input pipeline\n",
    "    ds = ds.batch(32).prefetch(1)\n",
    "    # tfds.dataset_as_numpy converts the tf.data.Dataset into an iterable of NumPy arrays\n",
    "    return tfds.as_numpy(ds)\n",
    "\n",
    "\n",
    "for epoch in range(\n",
    "    0\n",
    "):  # github actions can't run this, so we have to do this until we have GPU testing set up\n",
    "    start_time = time.time()\n",
    "    for x, y in get_train_batches():\n",
    "        x = jnp.tile(jnp.reshape(x, (len(x), c, h, w)), [1, 3, 1, 1]) / 255.0\n",
    "        y = jnp.array(y).astype(\"int8\")\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    train_acc = compute_accuracy(model, train_images / 255.0, train_labels)\n",
    "    test_acc = compute_accuracy(model, test_images / 255.0, test_labels)\n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "    print(\"Training set accuracy {}\".format(train_acc))\n",
    "    print(\"Test set accuracy {}\".format(test_acc))\n",
    "    print(loss(model, train_images / 255.0, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9de05cabd0065c957d7dba640313a9cffb6a721927d375cf35f9455db1b9cd1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
